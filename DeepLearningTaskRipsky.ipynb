{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtGtb8UXKNWLhzwBib2zPc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomasRipsky/Ai-Collab/blob/Deep_Learning/DeepLearningTaskRipsky.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPLEMENTATION OF THE NEURAL NETWORK"
      ],
      "metadata": {
        "id": "43bYj8idQeo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Corresponding imports\n",
        "import pandas as pd\n",
        "import numpy\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import parallel_coordinates\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "4w6YB3Q0CNe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data\n",
        "\n"
      ],
      "metadata": {
        "id": "Jst_t48wRhGX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlhWSqkvBeyU",
        "outputId": "d300b659-f2b4-4f47-b2d2-d5bfffc2d141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 366 entries, 0 to 365\n",
            "Data columns (total 35 columns):\n",
            " #   Column                                    Non-Null Count  Dtype \n",
            "---  ------                                    --------------  ----- \n",
            " 0   erythema                                  366 non-null    int64 \n",
            " 1   scaling                                   366 non-null    int64 \n",
            " 2   definite borders                          366 non-null    int64 \n",
            " 3   itching                                   366 non-null    int64 \n",
            " 4   koebner phenomenon                        366 non-null    int64 \n",
            " 5   polygonal papules                         366 non-null    int64 \n",
            " 6   follicular papules                        366 non-null    int64 \n",
            " 7   oral mucosal involvement                  366 non-null    int64 \n",
            " 8   knee and elbow involvement                366 non-null    int64 \n",
            " 9   scalp involvement                         366 non-null    int64 \n",
            " 10  family history                            366 non-null    int64 \n",
            " 11  melanin incontinence                      366 non-null    int64 \n",
            " 12  eosinophils in the infiltrate             366 non-null    int64 \n",
            " 13  PNL infiltrate                            366 non-null    int64 \n",
            " 14  fibrosis of the papillary dermis          366 non-null    int64 \n",
            " 15  exocytosis                                366 non-null    int64 \n",
            " 16  acanthosis                                366 non-null    int64 \n",
            " 17  hyperkeratosis                            366 non-null    int64 \n",
            " 18  parakeratosis                             366 non-null    int64 \n",
            " 19  clubbing of the rete ridges               366 non-null    int64 \n",
            " 20  elongation of the rete ridges             366 non-null    int64 \n",
            " 21  thinning of the suprapapillary epidermis  366 non-null    int64 \n",
            " 22  spongiform pustule                        366 non-null    int64 \n",
            " 23  munro microabcess                         366 non-null    int64 \n",
            " 24  focal hypergranulosis                     366 non-null    int64 \n",
            " 25  disappearance of the granular layer       366 non-null    int64 \n",
            " 26  vacuolisation and damage of basal layer   366 non-null    int64 \n",
            " 27  spongiosis                                366 non-null    int64 \n",
            " 28  saw-tooth appearance of retes             366 non-null    int64 \n",
            " 29  follicular horn plug                      366 non-null    int64 \n",
            " 30  perifollicular parakeratosis              366 non-null    int64 \n",
            " 31  inflammatory monoluclear inflitrate       366 non-null    int64 \n",
            " 32  band-like infiltrate                      366 non-null    int64 \n",
            " 33  Age                                       366 non-null    object\n",
            " 34  Class                                     366 non-null    int64 \n",
            "dtypes: int64(34), object(1)\n",
            "memory usage: 100.2+ KB\n"
          ]
        }
      ],
      "source": [
        "#We load the data from the database URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/dermatology.data\"\n",
        "new_names = ['erythema','scaling','definite borders','itching','koebner phenomenon','polygonal papules','follicular papules','oral mucosal involvement','knee and elbow involvement','scalp involvement','family history','melanin incontinence',\n",
        "'eosinophils in the infiltrate','PNL infiltrate','fibrosis of the papillary dermis','exocytosis','acanthosis','hyperkeratosis','parakeratosis','clubbing of the rete ridges','elongation of the rete ridges','thinning of the suprapapillary epidermis','spongiform pustule','munro microabcess','focal hypergranulosis','disappearance of the granular layer','vacuolisation and damage of basal layer','spongiosis',\n",
        "'saw-tooth appearance of retes','follicular horn plug','perifollicular parakeratosis','inflammatory monoluclear inflitrate','band-like infiltrate','Age','Class']\n",
        "dermatologyDB = pd.read_csv(url, names=new_names, skiprows=0, delimiter=',')\n",
        "dermatologyDB.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In order to fit the data in the neural network we must clear it form the ? values in age, thats why we use the following lambda function.\n",
        "dermatologyDB[\"Age\"]=dermatologyDB[\"Age\"].apply(lambda x: int(0) if x == \"?\" else int(x))\n",
        "\n",
        "#Here we split the data to work with X (everything except for the class) and Y (only the class of the sample)\n",
        "X=dermatologyDB.drop(labels='Class', axis=1)\n",
        "y=dermatologyDB.Class\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhcM-yqFAINT",
        "outputId": "2e5ae3bf-5bac-45e1-a6a8-135b1e89cf1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      2\n",
              "1      1\n",
              "2      3\n",
              "3      1\n",
              "4      3\n",
              "      ..\n",
              "361    4\n",
              "362    4\n",
              "363    3\n",
              "364    3\n",
              "365    1\n",
              "Name: Class, Length: 366, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing"
      ],
      "metadata": {
        "id": "9Vclh0yYAt-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Due to the nature of this problem, being this one a non balanced problem, the use of the stratifiedlkfold cross validator is the best option.\n",
        "#This validator generates train/test splits made by preserving the percentage of samples for each class\n",
        "y.unique()\n",
        "y2=pd.get_dummies(y)\n",
        "skf = StratifiedKFold(n_splits=2)\n",
        "skf.get_n_splits(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4_2X9hiA0nf",
        "outputId": "38466992-f266-4cf3-e1cb-16cd58e84e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating the model\n",
        "\n",
        "#Corresponding imports\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy_metrics=[]\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "\n",
        "  #Generation of training and testing samples\n",
        "  X_train, X_test = X.to_numpy()[train_index], X.to_numpy()[test_index]\n",
        "  y_train, y_test = y2.to_numpy()[train_index], y2.to_numpy()[test_index]\n",
        "\n",
        "  nb_classes = 6 #Number of unique medical conditions\n",
        "\n",
        "  #Adaptation to be have to create the tensor\n",
        "  y_train = numpy.asarray(y_train).astype(numpy.float32)\n",
        "  X_train = numpy.asarray(X_train).astype(numpy.float32)\n",
        "\n",
        "  # now we can generate the model\n",
        "  # create model\n",
        "  #We create a sequential model with an imput dimension of 34 and layers with 17,10 and 6 neurons\n",
        "  model = Sequential()\n",
        "  model.add(Dense(17, input_dim=34, activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(6, activation='sigmoid'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  #train the model\n",
        "  print(\"\\n-------------------------------------------------------------------------------------------------------\\n\")\n",
        "  model.fit(X_train, y_train, epochs=100, batch_size=5)\n",
        "\n",
        "  # calculating the metrics\n",
        "  print(\"\\nEvaluate on test data\\n\")\n",
        "  results = model.evaluate(X_test, y_test)\n",
        "  print(\"test loss, test acc:\", results)\n",
        "  accuracy_metrics.append(results[1])\n",
        "\n",
        "\n",
        "  #Making predictions\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  predicted_classes=numpy.argmax(y_pred,axis=1)\n",
        "  Y_test_onecolumn=numpy.argmax(y_test,axis=1)\n",
        "\n",
        "  #Creating the confusion matrix\n",
        "\n",
        "  print(\"\\n ----CONFUSION MATRIX----\\n\",confusion_matrix(Y_test_onecolumn, predicted_classes))\n",
        "\n",
        "  #Calculating other metrics\n",
        "\n",
        "  precision=precision_score(Y_test_onecolumn, predicted_classes, average='weighted',zero_division=1)\n",
        "  accuracy_metrics.append(precision)\n",
        "  print(\"\\nThe precision of the model is: \",precision)\n",
        "\n",
        "  recall=recall_score(Y_test_onecolumn, predicted_classes, average='weighted',zero_division=1)\n",
        "  accuracy_metrics.append(recall)\n",
        "  print(\"\\nThe recall of the model is: \",recall)\n",
        "\n",
        "  f1=f1_score(Y_test_onecolumn, predicted_classes, average='weighted',zero_division=1)\n",
        "  accuracy_metrics.append(f1)\n",
        "  print(\"\\nThe f1 score of the model is: \",f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0GqN7RdA4e7",
        "outputId": "b493b4b2-b339-41ae-c608-81aa49478aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch 1/100\n",
            "37/37 [==============================] - 1s 2ms/step - loss: 4.8302 - accuracy: 0.1803\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 2.1515 - accuracy: 0.3661\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.6577 - accuracy: 0.4481\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.4090 - accuracy: 0.4754\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.2319 - accuracy: 0.5902\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0779 - accuracy: 0.6284\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.9318 - accuracy: 0.7213\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7636 - accuracy: 0.8361\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.8798\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.9016\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.9290\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.9235\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.9399\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.9290\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.9399\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.9399\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.9508\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9563\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9617\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9399\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9508\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9617\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9617\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9563\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.9672\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9617\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9781\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9727\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9672\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9781\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9727\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9672\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9836\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9781\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9836\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9727\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9891\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9836\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9727\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9836\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9836\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9672\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9836\n",
            "Epoch 44/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9891\n",
            "Epoch 45/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9781\n",
            "Epoch 46/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9836\n",
            "Epoch 47/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9836\n",
            "Epoch 48/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9891\n",
            "Epoch 49/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9836\n",
            "Epoch 50/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9891\n",
            "Epoch 51/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9836\n",
            "Epoch 52/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9891\n",
            "Epoch 53/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9891\n",
            "Epoch 54/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9891\n",
            "Epoch 55/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9891\n",
            "Epoch 56/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9891\n",
            "Epoch 57/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9836\n",
            "Epoch 58/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9836\n",
            "Epoch 59/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9891\n",
            "Epoch 60/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9891\n",
            "Epoch 61/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9945\n",
            "Epoch 62/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9891\n",
            "Epoch 63/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9836\n",
            "Epoch 64/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9891\n",
            "Epoch 65/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9891\n",
            "Epoch 66/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9781\n",
            "Epoch 67/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9945\n",
            "Epoch 68/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9891\n",
            "Epoch 69/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9945\n",
            "Epoch 70/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9945\n",
            "Epoch 71/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9945\n",
            "Epoch 72/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9945\n",
            "Epoch 73/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9945\n",
            "Epoch 74/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9945\n",
            "Epoch 75/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9891\n",
            "Epoch 76/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9891\n",
            "Epoch 77/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9945\n",
            "Epoch 79/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9891\n",
            "Epoch 80/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9945\n",
            "Epoch 81/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9836\n",
            "Epoch 82/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9836\n",
            "Epoch 83/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9891\n",
            "Epoch 84/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9945\n",
            "Epoch 85/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9945\n",
            "Epoch 86/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9945\n",
            "Epoch 87/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9945\n",
            "Epoch 88/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9945\n",
            "Epoch 89/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9945\n",
            "Epoch 90/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9891\n",
            "Epoch 91/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9891\n",
            "Epoch 92/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9891\n",
            "Epoch 93/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9945\n",
            "Epoch 94/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9945\n",
            "Epoch 95/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9945\n",
            "Epoch 96/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9945\n",
            "Epoch 97/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9945\n",
            "Epoch 98/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9945\n",
            "Epoch 99/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9945\n",
            "Epoch 100/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9945\n",
            "\n",
            "Evaluate on test data\n",
            "\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9836\n",
            "test loss, test acc: [0.12869468331336975, 0.9836065769195557]\n",
            "6/6 [==============================] - 0s 4ms/step\n",
            "\n",
            " ----CONFUSION MATRIX----\n",
            " [[55  0  0  1  0  0]\n",
            " [ 0 31  0  0  0  0]\n",
            " [ 0  0 35  0  1  0]\n",
            " [ 0  1  0 23  0  0]\n",
            " [ 0  0  0  0 26  0]\n",
            " [ 0  0  0  0  0 10]]\n",
            "\n",
            "The precision of the model is:  0.9839797105849019\n",
            "\n",
            "The recall of the model is:  0.9836065573770492\n",
            "\n",
            "The f1 score of the model is:  0.9836383809408471\n",
            "\n",
            "-------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch 1/100\n",
            "37/37 [==============================] - 1s 3ms/step - loss: 2.3091 - accuracy: 0.3497\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.6821 - accuracy: 0.4317\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.3216 - accuracy: 0.4754\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 1.0566 - accuracy: 0.6175\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.8755 - accuracy: 0.6885\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.7431 - accuracy: 0.7432\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.7760\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.8087\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8361\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8525\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8579\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8525\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8470\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8798\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.8743\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8634\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8852\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.8907\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.8907\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9016\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.8907\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9016\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9235\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9290\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9290\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9344\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9508\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9399\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9617\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9672\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9672\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9727\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9781\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9781\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9891\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9891\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9945\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9945\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9891\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9945\n",
            "Epoch 47/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9891\n",
            "Epoch 49/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9891\n",
            "Epoch 50/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9945\n",
            "Epoch 53/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9945\n",
            "Epoch 54/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9945\n",
            "Epoch 55/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "\n",
            "Evaluate on test data\n",
            "\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9454\n",
            "test loss, test acc: [0.15270240604877472, 0.9453551769256592]\n",
            "6/6 [==============================] - 0s 2ms/step\n",
            "\n",
            " ----CONFUSION MATRIX----\n",
            " [[56  0  0  0  0  0]\n",
            " [ 0 25  0  5  0  0]\n",
            " [ 0  0 36  0  0  0]\n",
            " [ 0  5  0 20  0  0]\n",
            " [ 0  0  0  0 26  0]\n",
            " [ 0  0  0  0  0 10]]\n",
            "\n",
            "The precision of the model is:  0.9453551912568307\n",
            "\n",
            "The recall of the model is:  0.9453551912568307\n",
            "\n",
            "The f1 score of the model is:  0.9453551912568307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics.metrics import accuracy\n",
        "accuracy_metrics\n",
        "numpy.mean(accuracy_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok7kXpWYVcwM",
        "outputId": "61514891-60c5-434a-dfa0-2808b06fb58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9645314970648131"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONCLUSIONS"
      ],
      "metadata": {
        "id": "7WtsMS56ZkXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After implementing the neural network it is time to compare its results against the ones obtained previously in order to reach some conclusions:\n",
        "\n",
        "After some tests we can see that the metrics of the neural network are variable depending on the amount of layers, neurons per layers, and the amount of the epochs used. Also by maintining this values constant, the result may change depending on the behaviour of the neural network, giving different values with every use.\n",
        "\n",
        "Depending on each use, the behaviour of the neural network,the amount of layers or the values for epoch and neurons used, the results could be better or worse than the ones obteined in previous tasks.\n",
        "\n",
        "If we want to analize the neural network from the perspective of transparency, performance and metrics we could conclude that:\n",
        "1.   Talking about **metrics** as we said before, this can change so it depends on every use, but in general the results obteind are similar that the ones obteined before, but with the chance of getting better if you find the correct value of layers, epochs and neurons to use.\n",
        "2.   If we want to talk about **performance** it is clear that the neural network if by far the most demanding one, we can see it by only taking a look to the amount of time needed to run the algorithm, also by its nature that consist of trail and error with a big amount of data we can clearly see that it is a very demanding process, the other algorithms used before in the other hand are far fastter than this but could be not as scalable al this or not a powerfull.\n",
        "3. Finally if we talk about **transparency** we could say that the neural network is the least transparent of all, we can understand the logical functon of the algorithm and the matemathical process behind it, but it is by far the most complicated of the ones we have being using.\n",
        "\n",
        "It is clear that it is not the most \"simple\" or \"friendly\" algorithm to use or implement. But in the long run it is the most powerfull one. If you have the hardware power to use it, the corresponding amount of data to train it and test it and the knowledge of how to implement it and change their values at will, you have a really powerfull tool to work with. As almost every algorithm it has his faults, but if you have a large amount of data and the performance/time is not an issue, this this definitely the algorithm to use. It is the most powerfull and it becomes better over time if you give him more data.\n",
        "( + data = + accurate predictions )\n"
      ],
      "metadata": {
        "id": "lVRhUaltau46"
      }
    }
  ]
}